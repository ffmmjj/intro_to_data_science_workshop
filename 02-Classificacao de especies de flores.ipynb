{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemas de **classificação** representam uma ampla categoria de problemas de machine learning que envolvem a previsão de valores dentro de um conjunto finito e discreto de casos.\n",
    "\n",
    "Neste exemplo, construiremos um classificador para prever a qual espécie uma flor pertence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "iris = # carregue o arquivo 'datasets/iris.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exiba informações sobre o dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exiba as classes presentes nesse dataset usando o método unique() na coluna \"Class\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o método describe() para exibir estatísticas sobre o dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um scatterplot dos valores as colunas \"Sepal_length\" e \"Sepal_width\"\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sl = iris['Sepal_length']\n",
    "sw = iris['Sepal_width']\n",
    "\n",
    "# Crie um scatterplot dessas duas propriedades usando a função plt.scatter()\n",
    "# Atribua cores diferentes a cada exemplo do dataset de acordo com a classe à qual ele pertence\n",
    "\n",
    "# Atribua labels aos eixos X e Y\n",
    "\n",
    "# Exiba o gráfico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um scatterplot dos valores as colunas \"Petal_length\" e \"Pepal_width\"\n",
    "pl = iris['Petal_length']\n",
    "pw = iris['Petal_width']\n",
    "\n",
    "# Crie um scatterplot dessas duas propriedades usando a função plt.scatter()\n",
    "# Atribua cores diferentes a cada exemplo do dataset de acordo com a classe à qual ele pertence\n",
    "\n",
    "# Atribua labels aos eixos X e Y\n",
    "\n",
    "# Exiba o gráfico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classificação de espécies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos a classe [LogisticRegression do scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) para construir o classificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = # Crie um DataFrame com todas as features através da remoção da coluna \"Class\"\n",
    "t = # Pegue os valores da coluna \"Class\"\n",
    "RANDOM_STATE = 4321\n",
    "\n",
    "# Use o método train_test_plit() para dividir os dados em dois conjuntos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X, t, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o conjunto de treinamento para construir um modelo LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = # Crie um objeto LogisticRegression aqui\n",
    "# Treine o modelo usando os dados do conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o método score() do objeto LogisticRegression para avaliar a acurácia do modelo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o método score() do objeto LogisticRegression para avaliar a acurácia\n",
    "# do modelo no conjunto de teste"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspeção dos resultados\n",
    "\n",
    "Cálculos como o realizado acima geralmente não representam bem aquilo que queremos avaliar quando estamos resolvendo um problema de classificação. Ele apenas retorna o erro médio obtido entre as previsões e as classes reais do dataset de treinamento.\n",
    "\n",
    "Pense, por exemplo, no que aconteceria se você estivesse treinando um modelo para classificar se uma pessoa possui ou não uma doença em um contexto onde sabe-se que, normalmente, 99% ads pessoas não têm essa doença. O que poderia dar errado se calculássemos a taxa de erros e acertos do modelo como uma forma de avaliá-lo? *Dica: qual seria o valor dessa taxa de erros/acertos para um classificador \"hardcoded\" que sempre retorna 0 (isto é, ele sempre diz que a pessoa **não** tem a doença)?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas simples de acurácia geralmente não são recomendadas para problemas de classificação. Existem pelo menos três métricas que costumam ser usadas dependendo do contexto:\n",
    "\n",
    "* **Precisão**: esse número responde à seguinte pergunta: dentre os exemplos que o classificador disse que pertencem a uma classe, quantos de fato pertencem a ela?\n",
    "* **Recall**: esse número responde a uma pergunta levemente diferente da mostrada na Precisão: dentre os exemplos que *realmente* pertencem a uma classe, quantos o classificador conseguiu identificar?\n",
    "* **F1-Score**: essa métrica representa uma soma ponderada de precisão e recall - ela não apresenta uma interpretação intuitiva, mas a ideia é que o f1-score representa um meio-termo entre precisão e recall.\n",
    "\n",
    "<img src='images/Precisionrecall.svg'></img>\n",
    "Source: https://en.wikipedia.org/wiki/Precision_and_recall\n",
    "\n",
    "Outras métodos de avaliação para mdodelos de classificação incluem [análise de curva ROC](https://en.wikipedia.org/wiki/Receiver_operating_characteristic) e, relacionada a essa técnica, o conceito de [área sob a curva ROC](https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it).\n",
    "\n",
    "*Qual dessas métricas você priorizaria para o exemplo do classificador de doença descrito no parágrafo anterior? Quais são os custos para falsos positivos e falsos negativos nesse caso?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scikit-learn implementa uma função chamada \"classification_report\" que calcula as três métricas acima\n",
    "# para um dado classificador.\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Use essa função para exibir as métricas de classificação no modelo treinado anteriormente\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra técnica útil para inspecionar os resultados gerados por um modelo de classificação é a checagem da *matriz de confusão*. A matriz de confusão é uma matriz de dimensões *K x K* (onde K é o número de classes que o classificador pode identificar) que mostra, na posição **(i,j)**, quantos exemplos pertencentes à classe **i** foram classificados como pertencentes à classe **j**.\n",
    "\n",
    "Isso pode trazer insights a respeito de quais classes possuem a maior quantidade de classificações incorretas, por exemplo, e que portanto poderiam receber uma maior atenção por parte da pessoa cientista de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Use a função confusion_matrix para entender quais classes estão sendo classificadas incorretamente\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*No exemplo acima, o que você investigaria mais a fundo? Quais classes o classificador tem mais dificuldade de identificar corretamente?*"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
