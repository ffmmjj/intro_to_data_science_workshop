{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regression** problems involve the prediction of a continuous, numeric value from a set of characteristics.\n",
    "\n",
    "In this example, we'll build a model to predict house prices from characteristics like the number of rooms and the crime rate at the house location."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using the **pandas** package to read data.\n",
    "\n",
    "Pandas is an open source library that can be used to read formatted data files into tabular structures that can be processed by python scripts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you have a working installation of pandas by executing this cell\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we'll use the [Boston Housing dataset](http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) to predict house prices from characteristics like the number of rooms and distance to employment centers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read 'datasets/boston.csv' with pandas\n",
    "boston_housing_data = pd.read_csv('../datasets/boston.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas allows reading our data from different file formats and sources. See [this link](http://pandas.pydata.org/pandas-docs/stable/io.html) for a list of supported operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The head() method prints five entries by default. It can receive an optional argument to specify how many lines must be printed, like boston.head(n=10)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the head() method to print the first five entries in the dataset\n",
    "boston_housing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The info() method shows several details about the dataset, like how many entries there are in the dataset, what features are present, what's the data type of each feature and if there are any missing data in a feature.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the info() method to print information about the dataset\n",
    "boston_housing_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The describe() method only shows the summary statistics for columns of numeric types. If a column contains strings, for instance, it won't be able to calculate these descriptors.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the describe() method to print summary statistics of the dataset\n",
    "boston_housing_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reading our data into a pandas DataFrame and getting a broader view of the dataset, we can build charts to visualize tha \"shape\" of the data.\n",
    "\n",
    "We'll use python's *Matplotlib* library to create these charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you're given the following information about four datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = pd.read_csv('../datasets/anscombe.csv')\n",
    "\n",
    "for i in range(1, 5):\n",
    "    dataset = datasets[datasets.Source == 1]\n",
    "    print('Dataset {} (X, Y) mean: {}'.format(i, (dataset.x.mean(), dataset.y.mean())))\n",
    "\n",
    "print('\\n')\n",
    "for i in range(1, 5):\n",
    "    dataset = datasets[datasets.Source == 1]\n",
    "    print('Dataset {} (X, Y) std deviation: {}'.format(i, (dataset.x.std(), dataset.y.std())))\n",
    "\n",
    "print('\\n')\n",
    "for i in range(1, 5):\n",
    "    dataset = datasets[datasets.Source == 1]\n",
    "    print('Dataset {} correlation between X and Y: {}'.format(i, dataset.x.corr(dataset.y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all have roughly the same mean, standard deviations and correlation. How similar are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/638px-Anscombe%27s_quartet_3.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset is known as the [Anscombe's Quartet](https://en.wikipedia.org/wiki/Anscombe's_quartet) and it's used to illustrate how tricky it can be to trust only summary statistics to characterize a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing matplotlib for the first time may show a \n",
    "# warning message about the system's fonts\n",
    "import matplotlib.pyplot as plt\n",
    "# This line makes the graphs appear as cell outputs rather than in a separate window or file.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the house prices and average number of rooms to two separate variables\n",
    "prices = boston_housing_data.medv\n",
    "rooms = boston_housing_data.rm\n",
    "\n",
    "# Create a scatterplot of these two properties using plt.scatter()\n",
    "plt.scatter(rooms, prices)\n",
    "# Specify labels for the X and Y axis\n",
    "plt.xlabel('Number of rooms')\n",
    "plt.ylabel('House price')\n",
    "# Show graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the house prices and average number of rooms to two separate variables\n",
    "prices = boston_housing_data.medv\n",
    "nox = boston_housing_data.nox\n",
    "\n",
    "# Create a scatterplot of these two properties using plt.scatter()\n",
    "plt.scatter(nox, prices)\n",
    "# Specify labels for the X and Y axis\n",
    "plt.xlabel('Nitric oxide concentration')\n",
    "plt.ylabel('House price')\n",
    "# Show graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting house prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could see in the previous graphs that some features have a roughy linear relationship to the house prices. We'll use [Scikit-Learn's LinearRegression](scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) to model this data and predict house prices from other information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example below builds a LinearRegression model using the average number of rooms to predict house prices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract the predictors(the feature(s) that will be used to \n",
    "# predict the house prices) and the outcome(the house prices) into \n",
    "# different variables.\n",
    "\n",
    "x = boston_housing_data.rm.values.reshape(-1, 1) # Extract the values from the 'rm' column here\n",
    "y = boston_housing_data.medv.values.reshape(-1, 1) # Extract the values from the 'medv' column here\n",
    "\n",
    "print('x: {}'.format(x[0:3, :]))\n",
    "print('y: {}'.format(y[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The values.reshape(-1, 1) method call is necessary in this case because scikit-learn expects the predictors to be in matrix form - i.e. it must be a bi-dimensional array. Since we're using a single predictor, pandas returns it as a one-dimensional array, so we have to reshape it to a \"single-column matrix\". This step is not necessary when we use more that one predictor to fit a scikit-learn model, as will be seen in the next example.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the dataset isolated into predictor and outcome variables, they must be split into two different sets: a **training set** and a **test set**. This step is necessary if you want to be able to estimate how well the trained model will behave when it's used to predict prices of new houses: you must first use the *training set* to train the model and then calculate its error on the *test set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklean's train_test_plit() method to split our data into two sets.\n",
    "# See http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "xtr, xts, ytr, yts = train_test_split(x, y) # call train_test_split here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If we try to estimate the model performance in the same data that was used to train it, we might get a biased evaluation since the model was trained to minimize its error in this data set. In order to estimate how well the model will behave in practice, it must be evaluated in a separate data set.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression().fit(xtr, ytr) # fit a LinearRegression model into the training data.\n",
    "\n",
    "lr.predict(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use [Scikit-Learn's mean_squared_error](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) function to calculate the model's error in the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the test set to assess the model's performance.\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calculate the model's mean_squared_error here\n",
    "mean_squared_error(yts, lr.predict(xts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now use all the features in the dataset to predict house prices and see how it improves the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_housing_data.drop('medv', axis=1) # Use the drop() method to drop the 'medv' column and keep the others.\n",
    "y = boston_housing_data.medv # Extract the house values from the 'medv' column.\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*The drop() method will, by default, act on rows instead of columns. In order to drop columns, we have to pass an additional argument 'axis=1' to inform that we're dropping columns instead of rows.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklean's train_test_plit() method to split our data into two sets.\n",
    "# See http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtr, Xts, ytr, yts = train_test_split(X, y)\n",
    "\n",
    "# Use the training set to build a LinearRegression model\n",
    "lr = LinearRegression().fit(Xtr, ytr)\n",
    "\n",
    "# Calculate the model's mean_squared_error in the test set\n",
    "mean_squared_error(yts, lr.predict(Xts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What kind of enhancements could be done to get better results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One final observation about splitting datasets\n",
    "\n",
    "Data is usually split into three different sets:\n",
    "* **Training set**: this is the data used to actually train the machine learning model;\n",
    "* **Validation set (not shown in this workshop)**: This set is used to select the best machine learning model among different algorithms or hyperparameters. The idea is that you'd _not_ use this data set to directly train your model but you'd use it to choose the right algorithm, architecture, hyperparameters and so on during the training phase;\n",
    "* **Test set**: this is a set that is used to asess the model performance after the best model is trained and selected using the training and validation sets. This data set is ideally used only once to evaluate how the model would perform on completely unseen data.\n",
    "\n",
    "You can refer to [this post](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7) for more information. There are other popular approaches like [Cross-Validation](https://machinelearningmastery.com/k-fold-cross-validation/) for model tuning and evaluation, but they won't be covered during this workshop."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
