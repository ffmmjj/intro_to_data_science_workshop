{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemas de **regressão** envolvem a predição de um valor numérico contínuo a partir de um conjunto de característiacs.\n",
    "\n",
    "Neste exemplo, vamos construir um modelo para prever preços de casas a partir de características delas, como número de quartos e taxa de crimes na localização da casa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos o pacote **pandas** para ler os dados.\n",
    "\n",
    "Pandas é uma biblioteca de código aberto que permite a leitura de dados a partir de diversos formatos para uma estrutura tabular que pode ser acessada e processada por scripts Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando se a biblioteca está instalada corretamente e consegue ser importada\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste exercício, usaremos o dataset [Boston Housinh]((http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) para prever preços de casas a partir de características delas e de sua vizinhança."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregue o arquivo 'datasets/boston.csv' usando o pandas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas permite a leitura de nossos dados a partir de diferentes formatos. Veja [esse link](http://pandas.pydata.org/pandas-docs/stable/io.html) para uma lista de formatos suportados e as respectivas funções usadas para lê-los."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O tipo usado pelo pandas para representar essa tabela com nosso dataset carregado é chamada de `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o método head() para exibir as primeiras cinco linhas do dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*O método head() imprime as primeiras cinco linhas por padrão. Ele pode receber opcionalmente um argumento que especifique quantas linhas devem ser exibidas, como `boston.head(n=10)`.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o método info() para exibir algumas informações sobre o dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*O método info() exibe vários detalhes sobre o dataset, como a sua quantidade de linhas, quais  features estão presentes, qual é o tipo de cada feature e se existem valores em branco.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o método describe() apra exibir algumas estatísticas do dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*O método describe() apenas mostra estatísticas de features numéricas. Se uma feature contém strings, por exemplo, ele não será capaz de mostrar informações sobre ela.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualização de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após ler os dados em um DataFrame do pandas e ter obtido uma visão geral do dataset, podemos criar gráficos para visualizar o \"formato\" desses dados.\n",
    "\n",
    "Usaremos a biblitoeca *Matplotlib* para criar esses gráficos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suponha que lhe seja dada a seguinte informação sobre quatro datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 (X, Y) mean: (9.0, 7.500909090909093)\n",
      "Dataset 2 (X, Y) mean: (9.0, 7.500909090909093)\n",
      "Dataset 3 (X, Y) mean: (9.0, 7.500909090909093)\n",
      "Dataset 4 (X, Y) mean: (9.0, 7.500909090909093)\n",
      "\n",
      "\n",
      "Dataset 1 (X, Y) std deviation: (3.3166247903554, 2.031568135925815)\n",
      "Dataset 2 (X, Y) std deviation: (3.3166247903554, 2.031568135925815)\n",
      "Dataset 3 (X, Y) std deviation: (3.3166247903554, 2.031568135925815)\n",
      "Dataset 4 (X, Y) std deviation: (3.3166247903554, 2.031568135925815)\n",
      "\n",
      "\n",
      "Dataset 1 correlation between X and Y: 0.81642051634484\n",
      "Dataset 2 correlation between X and Y: 0.81642051634484\n",
      "Dataset 3 correlation between X and Y: 0.81642051634484\n",
      "Dataset 4 correlation between X and Y: 0.81642051634484\n"
     ]
    }
   ],
   "source": [
    "datasets = pd.read_csv('./datasets/anscombe.csv')\n",
    "\n",
    "for i in range(1, 5):\n",
    "    dataset = datasets[datasets.Source == 1]\n",
    "    print('Dataset {} (X, Y) mean: {}'.format(i, (dataset.x.mean(), dataset.y.mean())))\n",
    "\n",
    "print('\\n')\n",
    "for i in range(1, 5):\n",
    "    dataset = datasets[datasets.Source == 1]\n",
    "    print('Dataset {} (X, Y) std deviation: {}'.format(i, (dataset.x.std(), dataset.y.std())))\n",
    "\n",
    "print('\\n')\n",
    "for i in range(1, 5):\n",
    "    dataset = datasets[datasets.Source == 1]\n",
    "    print('Dataset {} correlation between X and Y: {}'.format(i, dataset.x.corr(dataset.y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos eles possuem aproximadamente a mesma média, desvio-padrão e correlação. Quão parecidos esses datasets devem ser?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/638px-Anscombe%27s_quartet_3.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse conjunto de datasets são conhecidos como o [Quarteto de Anscombe](https://en.wikipedia.org/wiki/Anscombe's_quartet) e eles costumam ser usados para ilustrar como confiar apenas em estatísticas como uma forma de caracterizar conjuntos de dados podem induzir a conclusões incorretas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Na primeira vez que o matplotlib é importado, pode ser exibido algum tipo\n",
    "# de alerta relacionado às fontes do sistema dependendo da sua configuração\n",
    "import matplotlib.pyplot as plt\n",
    "# Essa linha permite que os gráficos gerados apareçam diretamente no notebook\n",
    "# ao invés de serem abertos em uma janela ou arquivo separado.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraia os preços das casas e a quantidade média de cômodos em duas variáveis separadas\n",
    "prices = \n",
    "rooms = \n",
    "\n",
    "# Crie um scatterplot dessas duas features usando plt.scatter()\n",
    "\n",
    "# Especifique labels para os eixos X e Y\n",
    "\n",
    "# Exiba o gráfico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraia os preços das casas e o índice de poluição da vizinhança em duas variáveis separadas\n",
    "prices = \n",
    "nox = \n",
    "\n",
    "# Crie um scatterplot dessas duas features usando plt.scatter()\n",
    "\n",
    "# Especifique labels para os eixos X e Y\n",
    "\n",
    "# Exiba o gráfico\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Previsão de preços"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vimos nos gráficos anteriores que algumas features parecem ter uma relação linear com os preços das casas. Usaremos então a classe [LinearRegression to Scikit-Learn](scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) para modelar essa relação e conseguir prever preços de casas a partir dessas features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O exemplo abaixo constrói um modelo LinearRegression usando o número médio de cômodos para prever o preço da casa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primeiro, extraia os preditores (as features que serão usadas para\n",
    "# prever o preço das casas) e a saída (os preços das casas) em\n",
    "# variáveis separadas.\n",
    "\n",
    "x = # Extraia os valores da coluna 'rm' aqui\n",
    "y = # Extraia os valores da coluna 'medv' aqui\n",
    "\n",
    "print('x: {}'.format(x[0:3, :]))\n",
    "print('y: {}'.format(y[0:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*A chamada `values.reshape(-1, 1)` é necessária nesse caso porque o scikit-learn espera que os preditores estejam na forma de uma matriz - isto é, em um formato de array bidimensional. Como estamos usando apenas um preditor, o pandas acaba representando isso como um array unidimensional, então precisamos \"reformatá-lo\" em uma \"matriz de uma coluna só\". Esse passo não é necessário se estivermos usando mais de um preditor para treinar um modelo do scikit-learn, como será visto no próximo exemplo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora que temos o dataset isolado em preditores e saídas, eles precisam ser divididos em dois conjuntos diferentes: um **conjunto de treinamento** e um **conjunto de teste**.\n",
    "\n",
    "Esse passo é necessário caso você precise estimar o quão bem seu modelo treinado se comportará quando for usado para prever preços de novas casas: é necessário usar o conjunto de *treinamento* para treinar o modelo e então calcular a sua taxa de erros no conjunto de *teste*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use a função train_test_split() do scikit-learn para dividir os dados em dois conjuntos.\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE = 4321\n",
    "xtr, xts, ytr, yts = # Chame a função train_test_split aqui"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Se tentarmos estimar a performance do modelo no mesmo conjunto de dados que foi usado para treiná-lo, obteremos uma estimativa enviesada já que o modelo foi treinado para minimizar sua taxa de erro exatamente nos exemplos presentes no conjunto de treinamento. Para estimar corretamente o quão bem o modelo se comportará na prática, ele precisa se testado em um conjunto de dados com o qual ele nunca teve contato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = # Treine um modelo LinearRegression aqui usando o conjunto de treinamento\n",
    "\n",
    "lr.predict(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcule os preços previstos pelo modelo treinado\n",
    "predicted_prices = lr.predict(x)\n",
    "\n",
    "# Crie um scatterplot dessas duas propriedades usando plt.scatter()\n",
    "plt.scatter(rooms, prices)\n",
    "# Crie um line plot exibindo os valores previstos em vermelho\n",
    "plt.plot(rooms, predicted_prices, 'r')\n",
    "# Crie labels para os eixos X e Y\n",
    "plt.xlabel('Number of rooms')\n",
    "plt.ylabel('House price')\n",
    "# Exiba o gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agora usar a função [mean_squared_error do Scikit-Learn](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html) para calcular o erro total médio do modelo nos dados do conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use o conjunto de testes para avaliar a performace do modelo\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Calcule o mean_squared_error do modelo aqui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O erro aqui provavelmente será bem alto. Usaremos então todas as features do dataset como preditores para tentar prever os preços das casas e vamos checar o quanto isso melhora a performance do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = # Use o método drop() aqui para descartar a coluna 'medv' e manter as demais.\n",
    "y = # Extraia o preço das casas aqui a partir da coluna 'medv'.\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ANOTHER_RANDOM_STATE=1234\n",
    "Xtr, Xts, ytr, yts = # Dviida o dataset em treinamente e teste\n",
    "\n",
    "lr = # Use o conjunto de treinamento para treinar um modelo LinearRegression\n",
    "\n",
    "# Calcule o mean_squared_error do modelo no conjunto de teste aqui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Quais melhorias você acha que ainda poderiam ser feitas para se obter melhores resultados?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uma observação final sobre a divisão dos dados\n",
    "\n",
    "Os dados usados em machine learning geralmente são divididos em três partes:\n",
    "* **Conjunto de treinamento**: Os dados usados para se treinar o modelo;\n",
    "* **Conjunto de validação (não discutido nesse workshop)**: Esse conjunto é usado para selecionar o melhor modelo dentre diferentes algoritmos ou hiperparâmetros. A ideia é que você _não_ use esse conjunto para treinar seu modelo diretamente, mas sim para selecionar qual algoritmo, valores de hiperparâmetros, etc dão o melhor resultado durante a fase de treinamento;\n",
    "* **Conjunto de teste**: Este é um conjunto usado para estimar a performance do modelo após ter-se treinado e selecionado o modelo final que será usado na prática. Esse conjunto é idealmente usado apenas uma vez para avaliar o quão bem o modelo se comporta quando ele trabalha com dados com os quais ele nunca teve contato antes.\n",
    "\n",
    "Se quiser mais detalhes, pode checar [esse texto](https://towardsdatascience.com/train-validation-and-test-sets-72cb40cba9e7)(em inglês) para mais informações. Existem outras abordagens bastante populares como [Validação cruzada](https://machinelearningmastery.com/k-fold-cross-validation/) para se fazer seleção e avaliação de modelos mas elas não serão cobertas nesse workshop."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
